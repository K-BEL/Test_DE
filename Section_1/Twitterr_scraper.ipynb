{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des modules n√©cessaires\n",
    "from selenium import webdriver  # Importe la classe pour contr√¥ler le navigateur via Selenium\n",
    "from selenium.webdriver.common.by import By  # Importe les strat√©gies de recherche d'√©l√©ments\n",
    "from selenium.webdriver.common.keys import Keys  # Importe des touches clavier pour l'interaction\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # Importe les attentes explicites\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Importe les conditions attendues\n",
    "\n",
    "import pandas as pd  # Importe la biblioth√®que pandas pour manipuler les donn√©es tabulaires\n",
    "from tabulate import tabulate  # Importe une fonction pour afficher des tableaux de donn√©es\n",
    "import datetime  # Importe le module de manipulation de dates et heures\n",
    "import time  # Importe le module pour g√©rer les d√©lais de temps\n",
    "import json  # Importe le module pour manipuler le format JSON\n",
    "import os  # Importe le module pour interagir avec le syst√®me d'exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Selenium est une biblioth√®que de test automatis√©e largement utilis√©e pour contr√¥ler les navigateurs web de mani√®re programmatique. Elle peut √©galement √™tre utilis√©e pour extraire des donn√©es √† partir de sites web, comme Twitter, m√™me en l'absence d'une API officielle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suivre l'√©volution des followers, des likes, des retweets et des r√©ponses sur Twitter sans utiliser d'API peut √™tre complexe en raison de la nature dynamique du site et des limites du web scraping. Pour y parvenir, on peut extraire les premi√®res m√©triques (followers, likes, retweets, r√©ponses) lors de la premi√®re collecte, puis effectuer des collectes ult√©rieures √† intervalles r√©guliers pour suivre les changements. En comparant les nouvelles m√©triques avec les pr√©c√©dentes, on peut calculer les diff√©rences et mettre √† jour une base de donn√©es avec ces informations. Cependant, cette m√©thode n'est pas aussi pr√©cise ni en temps r√©el qu'une API officielle, peut rencontrer des limites et n√©cessite de respecter les termes d'utilisation du site. Utiliser une API officielle reste la m√©thode recommand√©e pour un suivi plus fiable et pr√©cis des m√©triques.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code initialise un navigateur Chrome en utilisant le pilote chromedriver.exe (ou un navigateur Edge avec msedgedriver.exe en d√©commentant la ligne appropri√©e). Ensuite, il acc√®de √† la page de connexion Twitter en utilisant la m√©thode .get().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12372\\4254219363.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\chromedriver.exe')\n",
    "#driver = webdriver.Edge(executable_path=r'C:\\Users\\LENOVO\\Desktop\\msedgedriver.exe')\n",
    "\n",
    "driver.get(\"https://twitter.com/login\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code cherche et remplit les champs de nom d'utilisateur et de mot de passe sur la page de connexion Twitter. Il localise d'abord le champ d'entr√©e du nom d'utilisateur en utilisant la m√©thode .find_element() avec By.NAME, puis utilise .send_keys() pour y entrer le nom d'utilisateur (\"USER123\" dans cet exemple). Ensuite, il trouve le bouton \"Next\" en utilisant une expression XPath et utilise .click() pour le cliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and fill in the username and password fields\n",
    "username_input = driver.find_element(By.NAME, \"text\")\n",
    "username_input.send_keys(\"YOUR_USERNAME\")\n",
    "next_button = driver.find_element(By.XPATH, \"//div[@role='button'][contains(.,'Next')]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code localise le champ de saisie du mot de passe sur la page de connexion Twitter en utilisant la m√©thode .find_element() avec By.NAME. Ensuite, il entre le mot de passe (\"PASS123\" dans cet exemple) dans le champ en utilisant .send_keys(). Enfin, il localise le bouton de connexion en utilisant une expression XPath et utilise .click() pour se connecter √† Twitter.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_input = driver.find_element(By.NAME, \"password\")\n",
    "password_input.send_keys(\"YOUR_PASSWROD\")\n",
    "login = driver.find_element(By.XPATH, \"//div[@role='button'][contains(.,'Log in')]\")\n",
    "login.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de Selenium pour ouvrir la page web twitter en utilisant le navigateur Edge ou chromedriver ainsi que sp√©cifier le nom d'utilisateur √† extraire les donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the username\n",
    "username_input = \"elonmusk\"  #K22Samay\n",
    "\n",
    "# Open the Nordstrom website\n",
    "#driver.get(\"https://google.com\")\n",
    "driver.get(f\"https://twitter.com/{username_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code cr√©e un chemin de fichier CSV en fonction du nom d'utilisateur saisi pr√©c√©demment et du r√©pertoire de profil. Ensuite, il v√©rifie si le fichier CSV existe d√©j√† √† cet emplacement en utilisant os.path.exists(). Si le fichier existe, il charge les donn√©es existantes dans un DataFrame √† l'aide de Pandas avec pd.read_csv(). Sinon, s'il n'existe pas, il cr√©e un DataFrame vide.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = rf'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\Profiles\\{username_input}.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(csv_file_path):\n",
    "    existing_data = pd.read_csv(csv_file_path)\n",
    "else:\n",
    "    existing_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualiser le navigateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les donn√©es de l'utilisateur (nom d'utilisateur, de profil, nombre de posts, de followers, de following, photo de profile, de couverture, bio, badge de v√©rification, date de naissance, joining, lien, cat√©gorie, localisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La m√©thode XPath est une technique utilis√©e dans Selenium pour localiser et extraire des √©l√©ments d'une page web. Elle consiste √† d√©finir un chemin d'acc√®s sp√©cifique √† un √©l√©ment en utilisant des balises, des attributs et des relations hi√©rarchiques entre les √©l√©ments HTML. Cela permet de cibler pr√©cis√©ment l'√©l√©ment souhait√©, m√™me si sa position ou sa structure change. Par exemple, \"//div[@class='nom-de-classe']\" cible tous les √©l√©ments <div> ayant la classe sp√©cifi√©e. En utilisant XPath, Selenium peut trouver et interagir avec des √©l√©ments tels que des champs de texte, des boutons et des liens sur une page web.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2023-08-11',\n",
       "  'time': '00:34:52',\n",
       "  'username': '@elonmusk',\n",
       "  'Profile_name': 'Elon Musk',\n",
       "  'account_status': 'verified',\n",
       "  'posts_number': '29.2K posts',\n",
       "  'Followers': '408',\n",
       "  'Following': '152.5M',\n",
       "  'bio': 'Blades of Glory',\n",
       "  'joined': 'Joined June 2009',\n",
       "  'birthdate': '-',\n",
       "  'link': '-',\n",
       "  'categories': '-',\n",
       "  'location': 'ùïè√ê',\n",
       "  'profile_pic': 'https://pbs.twimg.com/profile_images/1509808420030844929/ifEhyqHM_200x200.jpg',\n",
       "  'background_pic': 'https://pbs.twimg.com/profile_banners/3429950987/1666617954/1080x360'}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = []\n",
    "profile = driver.find_element(By.XPATH,f'//div[@class=\"css-1dbjc4n\"]')\n",
    "profile1 = driver.find_element(By.CSS_SELECTOR, '.css-1dbjc4n.r-1ifxtd0.r-ymttw5.r-ttdzmv')\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date = current_datetime.strftime(\"%Y-%m-%d\")  # Format: YYYY-MM-DD\n",
    "current_time = current_datetime.strftime(\"%H:%M:%S\")  # Format: HH:MM:SS\n",
    "\n",
    "\n",
    "\n",
    "username = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div[1]/div/div[2]/div/div/div/span\").text \n",
    "Profile_name = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div[1]/div/div[1]/div/div/span/span[1]\").text \n",
    "posts_number = profile.find_element(By.XPATH, \"//div[@class='css-1dbjc4n r-16y2uox r-1wbh5a2 r-1pi2tsx r-1777fci']//div[@class='css-1dbjc4n r-1habvwh']//div[@class='css-901oao css-1hf3ou5 r-1bwzh9t r-37j5jr r-n6v787 r-16dba41 r-1cwl3u0 r-bcqeeo r-qvutc0']\").text \n",
    "Followers = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[1]/a/span[1]/span').text \n",
    "Following = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[2]/a/span[1]/span').text \n",
    "\n",
    "\n",
    "try:\n",
    "   bio = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[3]/div/div').text \n",
    "\n",
    "except:\n",
    "   bio = \"-\"\n",
    "       \n",
    "try:\n",
    "   verification_badge_element = driver.find_element(By.CSS_SELECTOR, \"[data-testid='icon-verified']\")\n",
    "   v = 'verified'\n",
    "except:\n",
    "   try:\n",
    "      verification_badge_element = driver.find_element(By.XPATH, \"//svg[@data-testid='icon-verified']\")\n",
    "      v = 'verified'\n",
    "   except:\n",
    "      v = 'Non verified'\n",
    "       \n",
    "try:\n",
    "   joined = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserJoinDate']\").text\n",
    "except:\n",
    "   joined = \"-\"\n",
    "       \n",
    "try:\n",
    "   birthdate = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserBirthdate']\").text\n",
    "except:\n",
    "   birthdate = \"-\"\n",
    "   \n",
    "try:\n",
    "   link = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserUrl']\").text \n",
    "except:\n",
    "   link = \"-\"\n",
    "   \n",
    "try:\n",
    "   categories = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserProfessionalCategory']\").text \n",
    "except:\n",
    "   categories = \"-\"\n",
    "   \n",
    "try:\n",
    "   location = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserLocation']\").text \n",
    "except:\n",
    "   location = \"-\" \n",
    "\n",
    "try:\n",
    "   profile_pic = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[1]/div[1]/div[2]/div/div[2]/div/a/div[3]/div/div[2]/div/img\")\n",
    "   image_url = profile_pic.get_attribute('src')\n",
    "except:\n",
    "   profile_pic = \"-\"\n",
    "       \n",
    "try:\n",
    "   background_pic = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/a/div/div[2]/div/img\")\n",
    "   image_url1 = background_pic.get_attribute('src')\n",
    "except:\n",
    "   background_pic = \"-\"\n",
    "       \n",
    "   \n",
    "\n",
    "user_dict = {\n",
    "        'date' : current_date,\n",
    "        'time' : current_time,\n",
    "        'username': username,\n",
    "        'Profile_name': Profile_name,\n",
    "        'account_status' : v,\n",
    "        'posts_number': posts_number,\n",
    "        'Followers': Followers,\n",
    "        'Following': Following,\n",
    "        'bio': bio,\n",
    "        'joined' : joined,\n",
    "        'birthdate' : birthdate,\n",
    "        'link' : link,\n",
    "        'categories' : categories,\n",
    "        'location' : location,\n",
    "        'profile_pic' : image_url,\n",
    "        'background_pic' : image_url1\n",
    "        \n",
    "    }\n",
    "    \n",
    "# Add the dictionary to a list\n",
    "user_list.append(user_dict)\n",
    "user_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces lignes de code permettent de fusionner les nouvelles donn√©es extraites avec les donn√©es existantes, puis de sauvegarder le tout dans un fichier CSV. Tout d'abord, les nouvelles donn√©es (stock√©es dans le dictionnaire \"user_dict\") sont ajout√©es aux donn√©es existantes (dans \"existing_data\") en utilisant la fonction \"append\". Ensuite, le tableau combin√© est enregistr√© dans le fichier CSV sp√©cifi√© par \"csv_file_path\" en utilisant \"to_csv\", et finalement, le tableau mis √† jour est affich√© de mani√®re format√©e dans la console √† l'aide de \"tabulate\". Cela permet de stocker et d'afficher les informations collect√©es de mani√®re ordonn√©e.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ïí‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
      "‚îÇ    ‚îÇ date       ‚îÇ time     ‚îÇ username   ‚îÇ Profile_name   ‚îÇ account_status   ‚îÇ posts_number   ‚îÇ   Followers ‚îÇ Following   ‚îÇ bio             ‚îÇ joined           ‚îÇ birthdate   ‚îÇ link   ‚îÇ categories   ‚îÇ location   ‚îÇ profile_pic                                                                   ‚îÇ background_pic                                                       ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ  0 ‚îÇ 2023-08-10 ‚îÇ 00:00:49 ‚îÇ @elonmusk  ‚îÇ Elon Musk      ‚îÇ verified         ‚îÇ 29.2K posts    ‚îÇ         408 ‚îÇ 152.4M      ‚îÇ Blades of Glory ‚îÇ Joined June 2009 ‚îÇ -           ‚îÇ -      ‚îÇ -            ‚îÇ ùïè√ê         ‚îÇ https://pbs.twimg.com/profile_images/1683325380441128960/yRsRRjGO_200x200.jpg ‚îÇ https://pbs.twimg.com/profile_banners/44196397/1690621312/1080x360   ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  1 ‚îÇ 2023-08-10 ‚îÇ 23:31:36 ‚îÇ @elonmusk  ‚îÇ Elon Musk      ‚îÇ verified         ‚îÇ 29.2K posts    ‚îÇ         408 ‚îÇ 152.5M      ‚îÇ Blades of Glory ‚îÇ Joined June 2009 ‚îÇ -           ‚îÇ -      ‚îÇ -            ‚îÇ ùïè√ê         ‚îÇ https://pbs.twimg.com/profile_images/1666063330010710016/MwvfI8KZ_200x200.jpg ‚îÇ https://pbs.twimg.com/profile_banners/158478342/1680545848/1080x360  ‚îÇ\n",
      "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
      "‚îÇ  2 ‚îÇ 2023-08-11 ‚îÇ 00:34:52 ‚îÇ @elonmusk  ‚îÇ Elon Musk      ‚îÇ verified         ‚îÇ 29.2K posts    ‚îÇ         408 ‚îÇ 152.5M      ‚îÇ Blades of Glory ‚îÇ Joined June 2009 ‚îÇ -           ‚îÇ -      ‚îÇ -            ‚îÇ ùïè√ê         ‚îÇ https://pbs.twimg.com/profile_images/1509808420030844929/ifEhyqHM_200x200.jpg ‚îÇ https://pbs.twimg.com/profile_banners/3429950987/1666617954/1080x360 ‚îÇ\n",
      "‚ïò‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïõ\n"
     ]
    }
   ],
   "source": [
    "combined_data = existing_data.append(user_dict, ignore_index=True)\n",
    "\n",
    "combined_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(tabulate(combined_data, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce fragment de code d√©finit le chemin vers un fichier CSV pour stocker les tweets extraits. Il v√©rifie d'abord si le fichier CSV existe d√©j√†. S'il existe, il lit les donn√©es existantes √† partir du fichier CSV. Sinon, il cr√©e un DataFrame vide pour stocker les donn√©es. Cela permet de pr√©parer l'ajout des nouveaux tweets extraits aux donn√©es existantes ou de commencer avec un DataFrame vide si c'est la premi√®re fois que les donn√©es sont collect√©es.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_csv = rf'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\Tweets\\{username_input}_tweets.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(tweets_csv):\n",
    "    existing_data = pd.read_csv(tweets_csv)\n",
    "else:\n",
    "    existing_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger plusieurs pages pour extraire leurs tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue un d√©filement vers le bas de la page √† plusieurs reprises pour charger davantage de tweets. Il ex√©cute une boucle qui r√©duit la variable scrolls √† chaque it√©ration, puis utilise la m√©thode execute_script de Selenium pour faire d√©filer la page vers le bas en utilisant JavaScript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M√©thode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrolls = 7\n",
    "while True:\n",
    "    scrolls -= 1\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    time.sleep(3)\n",
    "    if scrolls < 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M√©thode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M√©thode 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets you want to extract\n",
    "desired_tweet_count = 20\n",
    "current_tweet_count = 0\n",
    "\n",
    "while current_tweet_count < desired_tweet_count:\n",
    "    tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "    current_tweet_count += len(tweets)\n",
    "    \n",
    "    if current_tweet_count >= desired_tweet_count:\n",
    "        break  # Stop if desired tweet count is reached\n",
    "    \n",
    "    # Scroll down to load more tweets\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)  # Adjust the scrolling pause time as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les tweets et leurs donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code extrait les donn√©es des tweets affich√©s sur la page actuelle de Twitter. Il parcourt la liste des √©l√©ments tweets et extrait les informations suivantes pour chaque tweet : la date et l'heure du tweet, le texte du tweet, le nombre de retweets, de likes et de r√©ponses, ainsi que les informations sur les m√©dias associ√©s (images ou vid√©os). Il tente d'extraire le contenu m√©dia en v√©rifiant d'abord s'il s'agit d'une image ou d'une vid√©o, puis r√©cup√®re le lien ou la source correspondant. Les informations extraites sont stock√©es dans une liste de dictionnaires appel√©e tweets_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait = WebDriverWait(driver, 10)\n",
    "tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "#tweets = wait.until(tweets_loaded)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date = current_datetime.strftime(\"%Y-%m-%d\")  # Format: YYYY-MM-DD\n",
    "current_time = current_datetime.strftime(\"%H:%M:%S\")  # Format: HH:MM:SS  \n",
    "        \n",
    "for item in tweets[0:]:\n",
    "\n",
    "        try:\n",
    "            date = item.find_element(By.XPATH, './/time').text + ' ' + 'ago'\n",
    "        except:\n",
    "            date = '[empty]'\n",
    "        #print(date)\n",
    "\n",
    "        try:\n",
    "            text = item.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "        except:\n",
    "            text = '[empty]'\n",
    "        \n",
    "        \n",
    "        retweet_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"retweet\"]').text\n",
    "        like_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"like\"]').text\n",
    "        reply_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"reply\"]').text  \n",
    "        views_count = item.find_element(By.XPATH, \"//span[@data-testid='app-text-transition-container']//span[@class='css-901oao css-16my406 r-poiln3 r-n6v787 r-1cwl3u0 r-1k6nrdp r-1e081e0 r-qvutc0']\").text\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        media_info_list = []\n",
    "        media_type = \" \"\n",
    "\n",
    "        try:\n",
    "            # Try to find a div element with data-testid=\"tweetPhoto\" for pictures\n",
    "            if item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n r-1adg3ll r-1ny4l3l']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//img[@class='css-9pa8cd']\"):\n",
    "                media_src = item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n r-1adg3ll r-1ny4l3l']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//img[@class='css-9pa8cd']\")[0].get_attribute(\"src\")\n",
    "                media_type = \"picture\"\n",
    "                media_dict = {\n",
    "                        'media_type': media_type,\n",
    "                        #'media_url': media_src\n",
    "                    }\n",
    "                media_info_list.append(media_dict)\n",
    "        except:\n",
    "            # If the picture div element is not found, try to find a div element with data-testid=\"videoComponent\" for videos\n",
    "            if item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//video[@aria-label='Embedded video']\") :\n",
    "                media_src  = item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//video[@aria-label='Embedded video']\")[0].get_attribute(\"src\")\n",
    "                media_type = \"video\"\n",
    "                media_dict = {\n",
    "                        'media_type': media_type,\n",
    "                        #'media_url': media_src\n",
    "                    }\n",
    "                media_info_list.append(media_dict)\n",
    "        \n",
    "\n",
    "        # Create the main dictionary for this tweet\n",
    "        tweets_dict = {\n",
    "            'actual_date': current_date,\n",
    "            'actual_time': current_time,\n",
    "            'datetime of post': date,\n",
    "            'text': text,\n",
    "            'media_info_list': media_info_list,  # Store media information as a list of dictionaries\n",
    "            'retweet_count': retweet_count,\n",
    "            'like_count': like_count,\n",
    "            'reply_count': reply_count,\n",
    "            #'views_count': views_count\n",
    "        }\n",
    "\n",
    "        # Add the dictionary to the list\n",
    "        tweets_list.append(tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:36:25',\n",
       "  'datetime of post': '3h ago',\n",
       "  'text': 'This platform is by far the best way to reach world leaders, CEOs and the cognoscenti in general',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '5,700',\n",
       "  'like_count': '44.2K',\n",
       "  'reply_count': '5,612'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:36:25',\n",
       "  'datetime of post': '23h ago',\n",
       "  'text': 'Great product engineering & design sessions today with the ùïè team!\\n\\nFuture is looking bright.',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '15.8K',\n",
       "  'like_count': '181.8K',\n",
       "  'reply_count': '12.8K'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': '3h ago',\n",
       "  'text': 'This platform is by far the best way to reach world leaders, CEOs and the cognoscenti in general',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '5,705',\n",
       "  'like_count': '44.2K',\n",
       "  'reply_count': '5,614'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': '23h ago',\n",
       "  'text': 'Great product engineering & design sessions today with the ùïè team!\\n\\nFuture is looking bright.',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '15.8K',\n",
       "  'like_count': '181.8K',\n",
       "  'reply_count': '12.8K'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': 'Aug 9 ago',\n",
       "  'text': 'Highly recommend doing this!',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '7,268',\n",
       "  'like_count': '52.2K',\n",
       "  'reply_count': '4,198'}]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code ajoute les donn√©es extraites des tweets √† l'ensemble de donn√©es existant (existing_data). Ensuite, il sauvegarde les donn√©es combin√©es dans un fichier CSV sp√©cifi√© par la variable tweets_csv. Enfin, il imprime le tableau mis √† jour dans la console en utilisant la fonction tabulate pour afficher les donn√©es de mani√®re format√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = existing_data.append(tweets_list, ignore_index=True)\n",
    "\n",
    "combined_data.to_csv(tweets_csv, index=False)\n",
    "\n",
    "print(tabulate(combined_data, headers='keys', tablefmt='fancy_grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
