{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des modules nÃ©cessaires\n",
    "from selenium import webdriver  # Importe la classe pour contrÃ´ler le navigateur via Selenium\n",
    "from selenium.webdriver.common.by import By  # Importe les stratÃ©gies de recherche d'Ã©lÃ©ments\n",
    "from selenium.webdriver.common.keys import Keys  # Importe des touches clavier pour l'interaction\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # Importe les attentes explicites\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Importe les conditions attendues\n",
    "\n",
    "import pandas as pd  # Importe la bibliothÃ¨que pandas pour manipuler les donnÃ©es tabulaires\n",
    "from tabulate import tabulate  # Importe une fonction pour afficher des tableaux de donnÃ©es\n",
    "import datetime  # Importe le module de manipulation de dates et heures\n",
    "import time  # Importe le module pour gÃ©rer les dÃ©lais de temps\n",
    "import json  # Importe le module pour manipuler le format JSON\n",
    "import os  # Importe le module pour interagir avec le systÃ¨me d'exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Selenium est une bibliothÃ¨que de test automatisÃ©e largement utilisÃ©e pour contrÃ´ler les navigateurs web de maniÃ¨re programmatique. Elle peut Ã©galement Ãªtre utilisÃ©e pour extraire des donnÃ©es Ã  partir de sites web, comme Twitter, mÃªme en l'absence d'une API officielle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Suivre l'Ã©volution des followers, des likes, des retweets et des rÃ©ponses sur Twitter sans utiliser d'API peut Ãªtre complexe en raison de la nature dynamique du site et des limites du web scraping. Pour y parvenir, on peut extraire les premiÃ¨res mÃ©triques (followers, likes, retweets, rÃ©ponses) lors de la premiÃ¨re collecte, puis effectuer des collectes ultÃ©rieures Ã  intervalles rÃ©guliers pour suivre les changements. En comparant les nouvelles mÃ©triques avec les prÃ©cÃ©dentes, on peut calculer les diffÃ©rences et mettre Ã  jour une base de donnÃ©es avec ces informations. Cependant, cette mÃ©thode n'est pas aussi prÃ©cise ni en temps rÃ©el qu'une API officielle, peut rencontrer des limites et nÃ©cessite de respecter les termes d'utilisation du site. Utiliser une API officielle reste la mÃ©thode recommandÃ©e pour un suivi plus fiable et prÃ©cis des mÃ©triques.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code initialise un navigateur Chrome en utilisant le pilote chromedriver.exe (ou un navigateur Edge avec msedgedriver.exe en dÃ©commentant la ligne appropriÃ©e). Ensuite, il accÃ¨de Ã  la page de connexion Twitter en utilisant la mÃ©thode .get().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_12372\\4254219363.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(r'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\chromedriver.exe')\n",
    "#driver = webdriver.Edge(executable_path=r'C:\\Users\\LENOVO\\Desktop\\msedgedriver.exe')\n",
    "\n",
    "driver.get(\"https://twitter.com/login\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code cherche et remplit les champs de nom d'utilisateur et de mot de passe sur la page de connexion Twitter. Il localise d'abord le champ d'entrÃ©e du nom d'utilisateur en utilisant la mÃ©thode .find_element() avec By.NAME, puis utilise .send_keys() pour y entrer le nom d'utilisateur (\"USER123\" dans cet exemple). Ensuite, il trouve le bouton \"Next\" en utilisant une expression XPath et utilise .click() pour le cliquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and fill in the username and password fields\n",
    "username_input = driver.find_element(By.NAME, \"text\")\n",
    "username_input.send_keys(\"YOUR_USERNAME\")\n",
    "next_button = driver.find_element(By.XPATH, \"//div[@role='button'][contains(.,'Next')]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code localise le champ de saisie du mot de passe sur la page de connexion Twitter en utilisant la mÃ©thode .find_element() avec By.NAME. Ensuite, il entre le mot de passe (\"PASS123\" dans cet exemple) dans le champ en utilisant .send_keys(). Enfin, il localise le bouton de connexion en utilisant une expression XPath et utilise .click() pour se connecter Ã  Twitter.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "password_input = driver.find_element(By.NAME, \"password\")\n",
    "password_input.send_keys(\"YOUR_PASSWROD\")\n",
    "login = driver.find_element(By.XPATH, \"//div[@role='button'][contains(.,'Log in')]\")\n",
    "login.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation de Selenium pour ouvrir la page web twitter en utilisant le navigateur Edge ou chromedriver ainsi que spÃ©cifier le nom d'utilisateur Ã  extraire les donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the username\n",
    "username_input = \"elonmusk\"  #K22Samay\n",
    "\n",
    "# Open the Nordstrom website\n",
    "#driver.get(\"https://google.com\")\n",
    "driver.get(f\"https://twitter.com/{username_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code crÃ©e un chemin de fichier CSV en fonction du nom d'utilisateur saisi prÃ©cÃ©demment et du rÃ©pertoire de profil. Ensuite, il vÃ©rifie si le fichier CSV existe dÃ©jÃ  Ã  cet emplacement en utilisant os.path.exists(). Si le fichier existe, il charge les donnÃ©es existantes dans un DataFrame Ã  l'aide de Pandas avec pd.read_csv(). Sinon, s'il n'existe pas, il crÃ©e un DataFrame vide.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = rf'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\Profiles\\{username_input}.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(csv_file_path):\n",
    "    existing_data = pd.read_csv(csv_file_path)\n",
    "else:\n",
    "    existing_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actualiser le navigateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les donnÃ©es de l'utilisateur (nom d'utilisateur, de profil, nombre de posts, de followers, de following, photo de profile, de couverture, bio, badge de vÃ©rification, date de naissance, joining, lien, catÃ©gorie, localisation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mÃ©thode XPath est une technique utilisÃ©e dans Selenium pour localiser et extraire des Ã©lÃ©ments d'une page web. Elle consiste Ã  dÃ©finir un chemin d'accÃ¨s spÃ©cifique Ã  un Ã©lÃ©ment en utilisant des balises, des attributs et des relations hiÃ©rarchiques entre les Ã©lÃ©ments HTML. Cela permet de cibler prÃ©cisÃ©ment l'Ã©lÃ©ment souhaitÃ©, mÃªme si sa position ou sa structure change. Par exemple, \"//div[@class='nom-de-classe']\" cible tous les Ã©lÃ©ments <div> ayant la classe spÃ©cifiÃ©e. En utilisant XPath, Selenium peut trouver et interagir avec des Ã©lÃ©ments tels que des champs de texte, des boutons et des liens sur une page web.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2023-08-11',\n",
       "  'time': '00:34:52',\n",
       "  'username': '@elonmusk',\n",
       "  'Profile_name': 'Elon Musk',\n",
       "  'account_status': 'verified',\n",
       "  'posts_number': '29.2K posts',\n",
       "  'Followers': '408',\n",
       "  'Following': '152.5M',\n",
       "  'bio': 'Blades of Glory',\n",
       "  'joined': 'Joined June 2009',\n",
       "  'birthdate': '-',\n",
       "  'link': '-',\n",
       "  'categories': '-',\n",
       "  'location': 'ğ•Ã',\n",
       "  'profile_pic': 'https://pbs.twimg.com/profile_images/1509808420030844929/ifEhyqHM_200x200.jpg',\n",
       "  'background_pic': 'https://pbs.twimg.com/profile_banners/3429950987/1666617954/1080x360'}]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_list = []\n",
    "profile = driver.find_element(By.XPATH,f'//div[@class=\"css-1dbjc4n\"]')\n",
    "profile1 = driver.find_element(By.CSS_SELECTOR, '.css-1dbjc4n.r-1ifxtd0.r-ymttw5.r-ttdzmv')\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date = current_datetime.strftime(\"%Y-%m-%d\")  # Format: YYYY-MM-DD\n",
    "current_time = current_datetime.strftime(\"%H:%M:%S\")  # Format: HH:MM:SS\n",
    "\n",
    "\n",
    "\n",
    "username = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div[1]/div/div[2]/div/div/div/span\").text \n",
    "Profile_name = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[2]/div[1]/div/div[1]/div/div/span/span[1]\").text \n",
    "posts_number = profile.find_element(By.XPATH, \"//div[@class='css-1dbjc4n r-16y2uox r-1wbh5a2 r-1pi2tsx r-1777fci']//div[@class='css-1dbjc4n r-1habvwh']//div[@class='css-901oao css-1hf3ou5 r-1bwzh9t r-37j5jr r-n6v787 r-16dba41 r-1cwl3u0 r-bcqeeo r-qvutc0']\").text \n",
    "Followers = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[1]/a/span[1]/span').text \n",
    "Following = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[5]/div[2]/a/span[1]/span').text \n",
    "\n",
    "\n",
    "try:\n",
    "   bio = profile.find_element(By.XPATH, '//*[@id=\"react-root\"]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[3]/div/div').text \n",
    "\n",
    "except:\n",
    "   bio = \"-\"\n",
    "       \n",
    "try:\n",
    "   verification_badge_element = driver.find_element(By.CSS_SELECTOR, \"[data-testid='icon-verified']\")\n",
    "   v = 'verified'\n",
    "except:\n",
    "   try:\n",
    "      verification_badge_element = driver.find_element(By.XPATH, \"//svg[@data-testid='icon-verified']\")\n",
    "      v = 'verified'\n",
    "   except:\n",
    "      v = 'Non verified'\n",
    "       \n",
    "try:\n",
    "   joined = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserJoinDate']\").text\n",
    "except:\n",
    "   joined = \"-\"\n",
    "       \n",
    "try:\n",
    "   birthdate = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserBirthdate']\").text\n",
    "except:\n",
    "   birthdate = \"-\"\n",
    "   \n",
    "try:\n",
    "   link = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserUrl']\").text \n",
    "except:\n",
    "   link = \"-\"\n",
    "   \n",
    "try:\n",
    "   categories = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserProfessionalCategory']\").text \n",
    "except:\n",
    "   categories = \"-\"\n",
    "   \n",
    "try:\n",
    "   location = profile1.find_element(By.CSS_SELECTOR, \"[data-testid='UserLocation']\").text \n",
    "except:\n",
    "   location = \"-\" \n",
    "\n",
    "try:\n",
    "   profile_pic = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/div/div[1]/div[1]/div[2]/div/div[2]/div/a/div[3]/div/div[2]/div/img\")\n",
    "   image_url = profile_pic.get_attribute('src')\n",
    "except:\n",
    "   profile_pic = \"-\"\n",
    "       \n",
    "try:\n",
    "   background_pic = profile.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/div[3]/div/div/div/a/div/div[2]/div/img\")\n",
    "   image_url1 = background_pic.get_attribute('src')\n",
    "except:\n",
    "   background_pic = \"-\"\n",
    "       \n",
    "   \n",
    "\n",
    "user_dict = {\n",
    "        'date' : current_date,\n",
    "        'time' : current_time,\n",
    "        'username': username,\n",
    "        'Profile_name': Profile_name,\n",
    "        'account_status' : v,\n",
    "        'posts_number': posts_number,\n",
    "        'Followers': Followers,\n",
    "        'Following': Following,\n",
    "        'bio': bio,\n",
    "        'joined' : joined,\n",
    "        'birthdate' : birthdate,\n",
    "        'link' : link,\n",
    "        'categories' : categories,\n",
    "        'location' : location,\n",
    "        'profile_pic' : image_url,\n",
    "        'background_pic' : image_url1\n",
    "        \n",
    "    }\n",
    "    \n",
    "# Add the dictionary to a list\n",
    "user_list.append(user_dict)\n",
    "user_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces lignes de code permettent de fusionner les nouvelles donnÃ©es extraites avec les donnÃ©es existantes, puis de sauvegarder le tout dans un fichier CSV. Tout d'abord, les nouvelles donnÃ©es (stockÃ©es dans le dictionnaire \"user_dict\") sont ajoutÃ©es aux donnÃ©es existantes (dans \"existing_data\") en utilisant la fonction \"append\". Ensuite, le tableau combinÃ© est enregistrÃ© dans le fichier CSV spÃ©cifiÃ© par \"csv_file_path\" en utilisant \"to_csv\", et finalement, le tableau mis Ã  jour est affichÃ© de maniÃ¨re formatÃ©e dans la console Ã  l'aide de \"tabulate\". Cela permet de stocker et d'afficher les informations collectÃ©es de maniÃ¨re ordonnÃ©e.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â•’â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â••\n",
      "â”‚    â”‚ date       â”‚ time     â”‚ username   â”‚ Profile_name   â”‚ account_status   â”‚ posts_number   â”‚   Followers â”‚ Following   â”‚ bio             â”‚ joined           â”‚ birthdate   â”‚ link   â”‚ categories   â”‚ location   â”‚ profile_pic                                                                   â”‚ background_pic                                                       â”‚\n",
      "â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚  0 â”‚ 2023-08-10 â”‚ 00:00:49 â”‚ @elonmusk  â”‚ Elon Musk      â”‚ verified         â”‚ 29.2K posts    â”‚         408 â”‚ 152.4M      â”‚ Blades of Glory â”‚ Joined June 2009 â”‚ -           â”‚ -      â”‚ -            â”‚ ğ•Ã         â”‚ https://pbs.twimg.com/profile_images/1683325380441128960/yRsRRjGO_200x200.jpg â”‚ https://pbs.twimg.com/profile_banners/44196397/1690621312/1080x360   â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  1 â”‚ 2023-08-10 â”‚ 23:31:36 â”‚ @elonmusk  â”‚ Elon Musk      â”‚ verified         â”‚ 29.2K posts    â”‚         408 â”‚ 152.5M      â”‚ Blades of Glory â”‚ Joined June 2009 â”‚ -           â”‚ -      â”‚ -            â”‚ ğ•Ã         â”‚ https://pbs.twimg.com/profile_images/1666063330010710016/MwvfI8KZ_200x200.jpg â”‚ https://pbs.twimg.com/profile_banners/158478342/1680545848/1080x360  â”‚\n",
      "â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  2 â”‚ 2023-08-11 â”‚ 00:34:52 â”‚ @elonmusk  â”‚ Elon Musk      â”‚ verified         â”‚ 29.2K posts    â”‚         408 â”‚ 152.5M      â”‚ Blades of Glory â”‚ Joined June 2009 â”‚ -           â”‚ -      â”‚ -            â”‚ ğ•Ã         â”‚ https://pbs.twimg.com/profile_images/1509808420030844929/ifEhyqHM_200x200.jpg â”‚ https://pbs.twimg.com/profile_banners/3429950987/1666617954/1080x360 â”‚\n",
      "â•˜â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•›\n"
     ]
    }
   ],
   "source": [
    "combined_data = existing_data.append(user_dict, ignore_index=True)\n",
    "\n",
    "combined_data.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(tabulate(combined_data, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce fragment de code dÃ©finit le chemin vers un fichier CSV pour stocker les tweets extraits. Il vÃ©rifie d'abord si le fichier CSV existe dÃ©jÃ . S'il existe, il lit les donnÃ©es existantes Ã  partir du fichier CSV. Sinon, il crÃ©e un DataFrame vide pour stocker les donnÃ©es. Cela permet de prÃ©parer l'ajout des nouveaux tweets extraits aux donnÃ©es existantes ou de commencer avec un DataFrame vide si c'est la premiÃ¨re fois que les donnÃ©es sont collectÃ©es.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_csv = rf'C:\\Users\\LENOVO\\Desktop\\Test_DE\\Section_1\\Tweets\\{username_input}_tweets.csv'\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.exists(tweets_csv):\n",
    "    existing_data = pd.read_csv(tweets_csv)\n",
    "else:\n",
    "    existing_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.refresh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger plusieurs pages pour extraire leurs tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code effectue un dÃ©filement vers le bas de la page Ã  plusieurs reprises pour charger davantage de tweets. Il exÃ©cute une boucle qui rÃ©duit la variable scrolls Ã  chaque itÃ©ration, puis utilise la mÃ©thode execute_script de Selenium pour faire dÃ©filer la page vers le bas en utilisant JavaScript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÃ©thode 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrolls = 7\n",
    "while True:\n",
    "    scrolls -= 1\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    time.sleep(3)\n",
    "    if scrolls < 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÃ©thode 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MÃ©thode 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets you want to extract\n",
    "desired_tweet_count = 20\n",
    "current_tweet_count = 0\n",
    "\n",
    "while current_tweet_count < desired_tweet_count:\n",
    "    tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "    current_tweet_count += len(tweets)\n",
    "    \n",
    "    if current_tweet_count >= desired_tweet_count:\n",
    "        break  # Stop if desired tweet count is reached\n",
    "    \n",
    "    # Scroll down to load more tweets\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)  # Adjust the scrolling pause time as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les tweets et leurs donnÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code extrait les donnÃ©es des tweets affichÃ©s sur la page actuelle de Twitter. Il parcourt la liste des Ã©lÃ©ments tweets et extrait les informations suivantes pour chaque tweet : la date et l'heure du tweet, le texte du tweet, le nombre de retweets, de likes et de rÃ©ponses, ainsi que les informations sur les mÃ©dias associÃ©s (images ou vidÃ©os). Il tente d'extraire le contenu mÃ©dia en vÃ©rifiant d'abord s'il s'agit d'une image ou d'une vidÃ©o, puis rÃ©cupÃ¨re le lien ou la source correspondant. Les informations extraites sont stockÃ©es dans une liste de dictionnaires appelÃ©e tweets_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait = WebDriverWait(driver, 10)\n",
    "tweets = driver.find_elements(By.XPATH, '//div[@data-testid]//article[@data-testid=\"tweet\"]')\n",
    "#tweets = wait.until(tweets_loaded)\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "current_date = current_datetime.strftime(\"%Y-%m-%d\")  # Format: YYYY-MM-DD\n",
    "current_time = current_datetime.strftime(\"%H:%M:%S\")  # Format: HH:MM:SS  \n",
    "        \n",
    "for item in tweets[0:]:\n",
    "\n",
    "        try:\n",
    "            date = item.find_element(By.XPATH, './/time').text + ' ' + 'ago'\n",
    "        except:\n",
    "            date = '[empty]'\n",
    "        #print(date)\n",
    "\n",
    "        try:\n",
    "            text = item.find_element(By.XPATH, './/div[@data-testid=\"tweetText\"]').text\n",
    "        except:\n",
    "            text = '[empty]'\n",
    "        \n",
    "        \n",
    "        retweet_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"retweet\"]').text\n",
    "        like_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"like\"]').text\n",
    "        reply_count = item.find_element(By.CSS_SELECTOR,'div[data-testid=\"reply\"]').text  \n",
    "        views_count = item.find_element(By.XPATH, \"//span[@data-testid='app-text-transition-container']//span[@class='css-901oao css-16my406 r-poiln3 r-n6v787 r-1cwl3u0 r-1k6nrdp r-1e081e0 r-qvutc0']\").text\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        media_info_list = []\n",
    "        media_type = \" \"\n",
    "\n",
    "        try:\n",
    "            # Try to find a div element with data-testid=\"tweetPhoto\" for pictures\n",
    "            if item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n r-1adg3ll r-1ny4l3l']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//img[@class='css-9pa8cd']\"):\n",
    "                media_src = item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n r-1adg3ll r-1ny4l3l']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//img[@class='css-9pa8cd']\")[0].get_attribute(\"src\")\n",
    "                media_type = \"picture\"\n",
    "                media_dict = {\n",
    "                        'media_type': media_type,\n",
    "                        #'media_url': media_src\n",
    "                    }\n",
    "                media_info_list.append(media_dict)\n",
    "        except:\n",
    "            # If the picture div element is not found, try to find a div element with data-testid=\"videoComponent\" for videos\n",
    "            if item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//video[@aria-label='Embedded video']\") :\n",
    "                media_src  = item.find_elements(By.XPATH, \"//div[@data-testid='cellInnerDiv']//div[@class='css-1dbjc4n']//div[@class='css-1dbjc4n r-eqz5dr r-16y2uox r-1wbh5a2']//video[@aria-label='Embedded video']\")[0].get_attribute(\"src\")\n",
    "                media_type = \"video\"\n",
    "                media_dict = {\n",
    "                        'media_type': media_type,\n",
    "                        #'media_url': media_src\n",
    "                    }\n",
    "                media_info_list.append(media_dict)\n",
    "        \n",
    "\n",
    "        # Create the main dictionary for this tweet\n",
    "        tweets_dict = {\n",
    "            'actual_date': current_date,\n",
    "            'actual_time': current_time,\n",
    "            'datetime of post': date,\n",
    "            'text': text,\n",
    "            'media_info_list': media_info_list,  # Store media information as a list of dictionaries\n",
    "            'retweet_count': retweet_count,\n",
    "            'like_count': like_count,\n",
    "            'reply_count': reply_count,\n",
    "            #'views_count': views_count\n",
    "        }\n",
    "\n",
    "        # Add the dictionary to the list\n",
    "        tweets_list.append(tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:36:25',\n",
       "  'datetime of post': '3h ago',\n",
       "  'text': 'This platform is by far the best way to reach world leaders, CEOs and the cognoscenti in general',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '5,700',\n",
       "  'like_count': '44.2K',\n",
       "  'reply_count': '5,612'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:36:25',\n",
       "  'datetime of post': '23h ago',\n",
       "  'text': 'Great product engineering & design sessions today with the ğ• team!\\n\\nFuture is looking bright.',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '15.8K',\n",
       "  'like_count': '181.8K',\n",
       "  'reply_count': '12.8K'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': '3h ago',\n",
       "  'text': 'This platform is by far the best way to reach world leaders, CEOs and the cognoscenti in general',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '5,705',\n",
       "  'like_count': '44.2K',\n",
       "  'reply_count': '5,614'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': '23h ago',\n",
       "  'text': 'Great product engineering & design sessions today with the ğ• team!\\n\\nFuture is looking bright.',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '15.8K',\n",
       "  'like_count': '181.8K',\n",
       "  'reply_count': '12.8K'},\n",
       " {'actual_date': '2023-08-11',\n",
       "  'actual_time': '00:37:12',\n",
       "  'datetime of post': 'Aug 9 ago',\n",
       "  'text': 'Highly recommend doing this!',\n",
       "  'media_info_list': [],\n",
       "  'retweet_count': '7,268',\n",
       "  'like_count': '52.2K',\n",
       "  'reply_count': '4,198'}]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code ajoute les donnÃ©es extraites des tweets Ã  l'ensemble de donnÃ©es existant (existing_data). Ensuite, il sauvegarde les donnÃ©es combinÃ©es dans un fichier CSV spÃ©cifiÃ© par la variable tweets_csv. Enfin, il imprime le tableau mis Ã  jour dans la console en utilisant la fonction tabulate pour afficher les donnÃ©es de maniÃ¨re formatÃ©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = existing_data.append(tweets_list, ignore_index=True)\n",
    "\n",
    "combined_data.to_csv(tweets_csv, index=False)\n",
    "\n",
    "print(tabulate(combined_data, headers='keys', tablefmt='fancy_grid'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
